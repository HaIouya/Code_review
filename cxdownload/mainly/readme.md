# summary
## 文件介绍
### 1.数据拆分（待优化）
```shell
sh run_workflow.sh
```

首先的话需要执行 run_workflow.sh ,然后获得一个新的csv文件，这个文件也就是利用 api 提取工作内容、岗位要求、技术栈。 （待优化，接口准确但是比较慢）
### 2.数据合并
```shell
python job_info_trans.py       #涉及到时间、省份新增列 

python job_merge.py         #设计工作岗位合并
```
然后的话执行一个 python脚本完成相似岗位的合并，这里主要是做了一个替换，将同一类的岗位名称修改为一个，方便后续进行岗位数量、工作地点等方面的统计。

### 3.星图绘制（待优化）

```shell
python draw_skills.py
```
这个脚本主要是开启一个窗口，用户可以在下滑窗口中选中一个，然后绘制一个该岗位的 技术栈 星图。同理下面的几个命令：

```shell
python draw_contents.py

python draw_requires.py
```

contents代表工作内容，requires代表岗位需求


## 优化工作

### 1. 工作地点，工作岗位的加入
- [ ] 首先来说的话，这个应该放置在第二点数据合并之后进行处理，更为关键的是怎么去处理呈现呢？

    - [x] 我把时间拆分成 三列 年 月 天。把省份 ， 市 作为两列， 补全空白公司信息，设置默认公司岗位招聘人数为1。 然后写入到一个新的csv文件中。
    这个转换的话是在 job_info_trans.py
    - [ ] 数据的呈现的话涉及到图像、岗位合并。然后同类统计呈现。

### 2. 数据切割
- [ ] 优化方向：争取不调用大模型接口，利用小模型或者规则
    - [x] 实验了一个qwen2-7B的模型也没有快，现在的话大概一千条三分钟左右。
    - [ ] 规则还未完成。 

### 3. draw_*.py
- [ ] tk窗口中文编码问题

- [ ] 多文件整合

提取岗位相关数据，包括年度、需求企业数量、人才需求量、按省需求量分布等。 排行榜显示 

- [x] 模型读取整理

### 4. 6.19 修复模型加载问题 
- [x] 使用模型加载的绝对路径，
其中涉及到的文件有 draw.py draw_*.py

### 5. 数据修复
- [x] 去掉前缀工作内容：\n 岗位职责：\n

    修复后的文件：Boss直聘_skills.csv

### 6. 规则指定呈现
- [ ] 设立一个 def num(job_name="job_name",province="province",company="company",year="year",month="month",day="day") 的函数，用来排序。当参数被赋予的时候，该参数固定，否则该参数为该参数的全集。 就比如来说限制了年月日的时间，那么就是相当于只看那时间的数据，但是不限制，就得看所有时间的数据。
  


