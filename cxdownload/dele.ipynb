{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('职位描述_技术栈.csv')\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理步骤：\n",
    "\n",
    "# 1. 清理岗位描述中的文本，去除无关字符。\n",
    "# 2. 清理技术栈，去除换行符和空格，并分割技能。\n",
    "# 3. 分割数据集为训练集、验证集和测试集。\n",
    "\n",
    "# 清理岗位描述\n",
    "data['岗位描述清洁'] = data['岗位描述'].str.replace('财务软件工程师任职要求：', '')\n",
    "data['岗位描述清洁'] = data['岗位描述清洁'].str.replace('岗位职责：', '')\n",
    "data['岗位描述清洁'] = data['岗位描述清洁'].str.replace('工作职责岗位职责：', '')\n",
    "data['岗位描述清洁'] = data['岗位描述清洁'].str.replace('工作职责：', '')\n",
    "data['岗位描述清洁'] = data['岗位描述清洁'].str.replace('任职要求：', '')\n",
    "data['岗位描述清洁'] = data['岗位描述清洁'].str.strip()\n",
    "\n",
    "# 清理技术栈，分割技能\n",
    "data['技术栈清洁'] = data['技术栈'].str.replace('\\n', ' ').str.split(r'\\s*;\\s*|\\s*,\\s*|\\s+')\n",
    "\n",
    "# 显示预处理后的数据\n",
    "data[['岗位描述清洁', '技术栈清洁']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 由于我们无法在这个环境中加载BERT模型，我们将演示如何准备数据。\n",
    "\n",
    "# 将数据分为岗位描述（X）和技术栈（y）\n",
    "X = data['岗位描述清洁'].tolist()\n",
    "y = data['技术栈清洁'].tolist()\n",
    "\n",
    "# 分割数据集为训练集和测试集（我们可以进一步将训练集分为训练集和验证集）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 显示分割结果的大小\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "# 加载预训练的BERT模型\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-chinese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来将文本转换为模型所需的格式\n",
    "def convert_examples_to_features(examples, labels, max_seq_length, tokenizer):\n",
    "    input_ids, attention_masks, token_type_ids, label_ids = [], [], [], []\n",
    "\n",
    "    for example, label in zip(examples, labels):\n",
    "        # 使用分词器标记化文本\n",
    "        bert_input = tokenizer.encode_plus(\n",
    "            example, \n",
    "            add_special_tokens=True, \n",
    "            max_length=max_seq_length, \n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        \n",
    "        input_ids.append(bert_input['input_ids'])\n",
    "        attention_masks.append(bert_input['attention_mask'])\n",
    "        token_type_ids.append(bert_input['token_type_ids'])\n",
    "        label_ids.append(label)\n",
    "\n",
    "    return (np.array(input_ids), np.array(attention_masks), np.array(token_type_ids)), np.array(label_ids)\n",
    "\n",
    "# 转换数据\n",
    "max_seq_length = 128\n",
    "train_features, train_labels = convert_examples_to_features(X_train, y_train, max_seq_length, tokenizer)\n",
    "test_features, test_labels = convert_examples_to_features(X_test, y_test, max_seq_length, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "# 编译模型\n",
    "optimizer = Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = BinaryCrossentropy(from_logits=True)\n",
    "metric = BinaryAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "model.evaluate(test_features, test_labels)\n",
    "\n",
    "# 进行预测\n",
    "predictions = model.predict(test_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
